---
layout: default
title: "CHI MNL | CHI2020 Study Group"
---
<style>
    .event-abstract img {
        width: 200px;
        margin-left: 10px;
        margin-top: -10px;
        float: right;
    }

    .event-abstract p {
        display: inline;
    }

    .event-speaker {
        width: 200px;
        margin-right: 25px;
        margin-bottom: 10px;
        margin-top: 5px;
        float: left;
    }

    .event-speaker img {
        width: 200px;
    }

    .event-speaker p {
        text-align: center;
    }

    .event-schedule li {
        margin-bottom: 5px;
    }

    .event-sched-item {
        list-style: none;
    }
</style>
<section  class = "pt-5 pb-5">
    <div class = "container">
        <h1 class = "font-weight-bolder">Post-CHI 2020 Study Group</h1>
        <h4 class = "mb-4">July 18 (Sat), 18:00-22:40 via Zoom</h4>
        <div class="event-abstract">
            <img src="../../assets/img/events/chi2020.png">
            <p>This year, the ACM CHI Conference on Human Factors in Computing Systems accepted 762 papers to be part of its main program. As a local post-conference event, we will be presenting short overviews of the papers to get a quick view of the latest works in HCI. This event was inspired by the annual CHI Study Group organized by the SIGCHI Japan Chapter.
            </p>
        </div>
        <h4 class = "mt-4">Why join the study group?</h4>
        <div class="event-details">
            <p>HCI is a very diverse field and it is steadily growing in terms of the number of exceptional contributions and the emergence of new lines of research. For example in 2021, a growing number of contributions in critical computing and computational interaction led to the creation of new subcommittees in the conference. The study group aims to quickly get an overview of the new HCI research contributions published at the premier HCI conference. After this event, we hope that the participants can identify topics and problems that they are interested in and start new research projects.</p>
            <p>We also invited Filipino researchers who have accepted papers at CHI 2020. We will have <a href="https://www.gierad.com/" target="_blank">Gierad Laput</a> from Apple as our Keynote speaker and <a href="https://www.bsolgado.com/" target="_blank">Benedict Olgado</a> from UC Irvine for an invited talk about his recent work.</p>
            <p>In 2021, the CHI conference will be held in Japan for the first time. We hope that this event can inspire the Filipino HCI community to work on exceptional submissions.</p>
        </div>
        <h4 class = "mt-4">Keynote</h4>
        <div class="event-details">
            <div class="event-speaker">
                <img src="../../assets/img/events/gierad_laput.jpg">
            </div>
            <h5><a href="https://www.gierad.com/" target="_blank">Gierad Laput</a>, Apple</h5>
            <p>As computing proliferates into everyday life, systems that understand people’s context of use are of paramount importance. Regardless of whether the platform is a mobile device, a wearable, or embedded in the environment, context offers an implicit dimension that will become highly important if we are to power more human-centric experiences. Context-driven sensing will become a foundational element for many high-impact applications, from specific domains such as elder care, health monitoring, and empowering people with disabilities, to much broader areas such as health and novel interactive experiences. In this talk, I discuss the construction and evaluation of sensing technologies that can be practically deployed and yet still greatly enhance contextual awareness, primarily drawing upon machine learning to unlock a wide range of applications. I discuss algorithms and pipelines that extract meaningful signals and patterns from sensor data to enable high-level abstraction and interaction. I also discuss system and human-centric challenges, and I conclude with a vision of how rich contextual awareness can enable more powerful experiences across broader domains.</p>
        </div>
        <h4 class = "mt-4">Invited</h4>
        <div class="event-details">
            <div class="event-speaker">
                <img src="../../assets/img/events/bono_olgado.jpeg">
            </div>
            <h5><a href="https://www.bsolgado.com/" target="_blank">Benedict Olgado</a>, UC Irvine</h5>
            <b>[Honorable Mention] Determining the Extractive Casting Mold of Intimate Platforms through Document Theory</b>
            <p>This paper introduces document theory as a mechanism to analyze intimate platforms as sociotechnical systems. The theory, developed in documentation studies and applied to HCI, focuses on the casting mold or how agents, through particular means and modes, produce documents that govern social relations. We studied the process of creating a profile by identifying and mapping out the fields asked among the ten most popular online dating apps in the US. By looking at dating profiles as documents and their creation as a process of documentation, we argue that the current casting mold of these intimate platforms is designed to extract profit via invisibilization of labor in digital networks leading to the emergence of a constrained rational market agent. Our study illustrates how document theory makes visible the assumptions of technological systems, calling on us to imagine alternatives beyond incremental design changes given broader structural realities of market and power.</p>
        </div>
        <h4 class = "mt-4">Program</h4>
        <div class="event-details">
            <ul class="event-schedule">
                <li class="event-sched-item">18:00-18:10	>> <b>Opening Remarks</b></li>
                <li class="event-sched-item">18:10-19:40	>> <b>Free selection sessions</b> <i>(17 sessions)</i></li>
                <ul>
                    <li>6 | Portrayals & social media by <i>Joshua Manzano</i></li>
                    <li>11 | A closer look at players by <i>Romeo Peña</i></li>
                    <li>29 | Perception of visualizations by <i>Unisse Chua</i></li>
                    <li>32 | Political movement by <i>Ian Ona</i></li>
                    <li>36 | Automotive & pedestrian interfaces by <i>Briane Samson</i></li>
                    <li>38 | Designing for health by <i>Paolo Delos Reyes</i></li>
                    <li>53 | Gamifying & play by <i>Geremiah Marasigan</i></li>
                    <li>96 | Tutoring & learning by <i>TJ Monserrat</i></li>
                    <li>107 | On-body interaction by <i>Tyrone Sta. Maria</i></li>
                    <li>112 | AI/ML & seeing through the black box by <i>Ralph Regalado</i></li>
                    <li>140 | Emotional interaction by <i>Adrienne Soliven</i></li>
                    <li>154 | Human factors in design by <i>Thomas Rafael Cruz</i></li>
                    <li>155 | Engineering design & modelling by <i>Jordan Deja</i></li>
                    <li>23 | Privacy theory & information disclosure by <i>Pranjal Jain</i></li>
                    <li>106 | Privacy & security user experience by <i>Pranjal Jain</i></li>
                    <li>118 | Privacy perceptions & concerns by <i>Pranjal Jain</i></li>
                    <li>138 | Communities & social aspects of privacy by <i>Pranjal Jain</i></li>
                </ul>
                <li class="event-sched-item">19:40-20:00 >> <b>Break</b> Please grab some dinner.</li>
                <li class="event-sched-item">20:00-20:30 >> <b>Curated sessions</b> <i>(5 sessions)</i></li>
                <ul>
                    <li>56 | (mis)Information & fake news by <i>Ralph Regalado</i></li>
                    <li>71 | Understanding & supporting mental health by <i>Kyle Santiago</i></li>
                    <li>98 | Augmenting work & productivity by <i>Briane Samson</i></li>
                    <li>117 | Inclusiveness & diversity by <i>Jen Teves</i></li>
                    <li>149 | Inclusive research methods by <i>Jen Teves</i></li>
                </ul>
                <li class="event-sched-item">20:30-21:10 >> <b>Filipino research @ CHI2020</b></li>
                <ul>
                    <li><b>[LBW] Are Two Heads Better than One? Exploring Two-Party Conversations for Car Navigation Voice Guidance</b> by <i>Briane Samson</i></li>
                    <li><b>[LBW] ViTune: A Visualizer Tool to Allow the Deaf and Hard of Hearing to See Music With Their Eyes</b> by <i>Jordan Deja</i></li>
                    <li><b>[Honorable Mention] Determining the Extractive Casting Mold of Intimate Platforms through Document Theory</b> by <i>Benedict Olgado, UC Irvine</i></li>
                </ul>
                <li class="event-sched-item">21:30-22:30 >> <b>Keynote by Gierad Laput of Apple</b></li>
                <li class="event-sched-item">22:30-22:40 >> <b>Closing</b></li>
            </ul>
        </div>
    </div>
</section>

<section  class = "pt-5 pb-5 bg-light">
    <div class = "container">
        <h4 class = "mt-4">How do I participate?</h4>
        <p>People who would like to present CHI papers must do the following steps:</p>
        <ol>
            <li><a href="https://forms.gle/hbnukYB58DHzmX7d6">Register</a> as a presenter by July 11 (F). We will use the details from your registration to send the links to the Zoom meeting. </li>
            <li>Identify the <a href="https://docs.google.com/spreadsheets/d/1aqK7i3pdSCKhvsVvy1z5LxCx-zN3b091ZnMBjm688YE/edit?usp=sharing" target="_blank">sessions</a> you would like to present by July 11 (F).</li>
        </ol>
        <h4 class = "mt-4">How do I select a session to present?</h4>
        <p>Please go to the list of CHI2020 sessions and select the sessions you want to read and present papers for. After you have decided, enter your full name (same as the one you used for registration) in the “Presenter” column of your chosen sessions. You can select more than one session if your current schedule and workload allows. This is a first come first serve basis. Please do not overwrite or delete the names of other people.</p>
        <p>Each session has around 5-6 papers and only one person can present for all papers. However, it is up to you if you want to share the reading load with other people.</p>
        <h4 class = "mt-4">There are too many papers in a session! How do I read them all on time?</h4>
        <p>For this study group, we advise you to be strategic in reading multiple papers. We know that you have other things on your plate so we do not expect you to read the papers thoroughly as you would typically do in an extensive literature review. The goal of the study group and presentations is to extract the important aspects and significant contributions of the paper, in order to inspire future projects. </p>
        <h4 class = "mt-4">What do I need to prepare for the presentation?</h4>
        <p>On the day of the study group, presenters will be given a maximum of 1 minute per paper. For example, if you volunteered to present a session with 5 papers, you have a maximum of 5 minutes to present them all. </p>
        <p>Presenters are required to make one slide per paper and consolidate them in one PDF. Please read through the guidelines for preparing the presentation materials.</p>
    </div>
</section>

<section  class = "pt-5 pb-5">
    <div class = "container">
        <h3 class = "font-weight-bolder" >Guidelines for Making Presentation Materials</h3>
        <p>All presenters are advised to follow the instructions in this guide to ensure successful presentations.</p>
        <h4 class = "mt-4">Important Details</h4>
        <ul>
            <li>Deadline of Submitting Presentation Materials - <span class = "font-weight-bold">July 11 (Saturday), 23:59 PST</span></li>
            <li>Upload your consolidated slides to this <a href="https://drive.google.com/drive/folders/1Cmf4Ov44D0P6ricGq3t_7Qaaf05t4MAx?usp=sharing" target="_blank">Google Drive</a></li>
            <li>Make 1 slide per paper. Maximize the use of images and diagrams</li>
            <li>Consolidate all slides for each session in 1 PDF</li>
            <li>Aspect ratio of slides - <span class = "font-weight-bold">16:9</span></li>
            <li>Sample slides - <a href="https://drive.google.com/file/d/1Ao8VUdD4GUqMoYoOpqazognKzSphCcb7/view?usp=sharing" target="_blank">1</a>, <a href="https://drive.google.com/file/d/1MjlZksIEPplahPEQn-zBB5D5z9fhzkZK/view?usp=sharing" target="_blank">2</a>, <a href="https://drive.google.com/file/d/1cIiD5Ci9-L0Ns_8jFQh9PYTsvih4wSpe/view?usp=sharing" target="_blank">3</a></li>
        </ul>
        <h4 class = "mt-4">Download Papers from ACM DL</h4>
        <p>Search for your selected session(s) in the <a href="https://programs.sigchi.org/chi/2020/program" target="_blank">CHI2020 Web Program</a>. Each paper has a link to their page in the ACM Digital Library.</p>
        <p>You can download all papers from the ACM Digital Library for free. If you are not an ACM or SIGCHI member, this free access is only available until June 30 (because of COVID-19 support). If you cannot download it before that date, please send an email to <span class = "font-weight-bold">sigchimnl@gmail.com</span> and we will download them for you.</p>
        <h4 class = "mt-4">Slides per Paper</h4>
        <p>Please make 1 slide per paper. Since you only have a maximum of 1 minute to present each paper, we advise you to focus on providing an effective summary of the main contributions and interesting aspects of the paper. In each slide, we expect to see the following:</p>
        <ul>
            <li>Paper title</li>
            <li>Author & affiliation</li>
            <li>Figures and text that best describe ANY of the following:</li>
            <ul>
                <li>Research Problem/Motivation</li>
                <li>Contributions</li>
                <li>Interesting Findings</li>
            </ul>
        </ul>
        <h4 class = "mt-4">Consolidated PDF per Session</h4>
        <p>The consolidated PDF per session must contain the following:</p>
        <ul>
            <li>Title slide which contains the name of the session and the presenter’s name and affiliation</li>
            <li>Paper slides</li>
        </ul>
        <p>Please name your PDF files as &lt;session number&gt;_&lt;presenter name&gt;.pdf. For example, 23_samson.pdf</p>
    </div>
</section>
